{
  "topic_num": 30,
  "check_pt_ntm_model_path": null,
  "ntm_warm_up_epochs": 200,
  "model_path": "checkpoint_ntm/",
  "target_sparsity": 0.85,
  "topic_type": "z",
  "in_file": "cleaned.txt",
  "learning_rate_ntm": 0.0005,
  "two_stage": false,
  "only_train_ntm": false,
  "load_pretrain_ntm": false,
  "use_topic_represent": true,
  "dataset_str": "hep_small",
  "dropout_rate": 0.5,
  "learning_rate": 0.005,
  "seed": 1566911445,
  "device": "cpu",
  "patience": 50,
  "log_interval": 2,
  "epochs": 2000,
  "learning_rate_decay_patience": 10,
  "learning_rate_decay_factor": 0.8,
  "weight_decay": 0.0005,
  "model": "HeteroGAT",
  "dataset": "data/word_data/hep_small/hep_small.pickle.bin",
  "hidden_dim": 64,
  "out_dim": 3,
  "aggr_func": "mlp",
  "node_feature": "one_hot",
  "num_layer": 2,
  "topwords": 10,
  "toptopic": 2,
  "verbose": true,
  "num_head": 1,
  "residual": false,
  "lamuda": 0.001,
  "test_loss": 0.7208591103553772,
  "test_f1": 0.6914805624483044,
  "macro_test_f1": 0.722990271377368,
  "test_acc": 0.692307710647583,
  "actual_epochs": 142,
  "val_acc_max": 0.7179487347602844,
  "val_loss_min": 1.8495678901672363,
  "total_time": 57.92536687850952
}
